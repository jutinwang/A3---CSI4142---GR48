{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Group 48 - Assignment 3 - Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this report, we perform an empirical study in which we evaluate a decision tree approach on a classification task.\n",
    "\n",
    "1. Clean the data \n",
    "2. (Optional) Groups different numerical values into bins or buckets \n",
    "3. Conduct an EDA (Exploritory Data Analysis) to visualize data and find outliers in the features using LOF (Local Outlier Factor)\n",
    "4. Explore the DecisionTreeClassifier method suggested in scikit-learn and choose a baseline setting by looking at the parameters (splitting criterion (gini, entropy), max_depth, min_samples_split, etc)\n",
    "5. Program a feature aggregator to create 2 additional features\n",
    "6. Conduct an empirical study\n",
    "7. Analyize the results\n",
    "8. Discuss the outliers and feature aggregation, as well as the results on the unseen test set compare to the cross-validation results\n",
    "\n",
    "#### Group 48 Members\n",
    "- Ali Bhangu - 300234254\n",
    "- Justin Wang - 300234186\n",
    "\n",
    "<br>\n",
    "\n",
    "## Dataset Description: Iris Dataset\n",
    "\n",
    "- **Dataset Name:** Iris Dataset  \n",
    "- **Author:** Himanshi Nakrani \n",
    "- **Purpose:** This dataset was found on Kaggle.com, and is used in numerous data science projects across the world. For our purposes, this will serve as the dataset we use for Assignment 3 Part 2. \n",
    "- **Link:** https://www.kaggle.com/datasets/himanshunakrani/iris-dataset\n",
    "---\n",
    "\n",
    "### Dataset Shape\n",
    "- **Rows:** 150  \n",
    "- **Columns:** 5  \n",
    "\n",
    "---\n",
    "\n",
    "### Features & Descriptions  \n",
    "\n",
    "| Feature Name    | Data Type  | Category    | Description |\n",
    "|----------------|------------|-------------|-------------|\n",
    "| `sepal_length` | Float      | Numerical   | Length of the sepal in cm |\n",
    "| `sepal_width`  | Float      | Numerical   | Width of the sepal in cm |\n",
    "| `petal_length` | Float      | Numerical   | Length of the petal in cm |\n",
    "| `petal_width`  | Float      | Numerical   | Width of the petal in cm |\n",
    "| `species`      | String     | Categorical | The species of the iris flower (Setosa, Versicolor, Virginica) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as npy\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import os as os\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing iris.csv found. Deleting and re-extracting...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     00    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1006  100  1006    0     0   2840      0 --:--:-- --:--:-- --:--:--  2840\n",
      "Extracting dataset...\n",
      "Archive:  iris-dataset.zip\n",
      "  inflating: ./iris.csv              \n",
      "Dataset loaded successfully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "zip_path = \"iris-dataset.zip\"\n",
    "csv_path = \"iris.csv\"  # Adjust this if the extracted file has a different name\n",
    "\n",
    "# Delete existing CSV if present\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Existing {csv_path} found. Deleting and re-extracting...\")\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# Download dataset using curl (Bash command in Jupyter Notebook)\n",
    "!curl -L -o {zip_path} https://www.kaggle.com/api/v1/datasets/download/himanshunakrani/iris-dataset\n",
    "\n",
    "# Extract the ZIP file in the current folder\n",
    "print(\"Extracting dataset...\")\n",
    "!unzip -o {zip_path} -d .\n",
    "\n",
    "# Verify that the CSV exists after extraction\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {csv_path}. Ensure the ZIP file was correctly extracted.\")\n",
    "\n",
    "# Load dataset\n",
    "irisSet = pd.read_csv(csv_path)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "irisSet.head()\n",
    "irisSet.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### a) Clean Data\n",
    "\n",
    "Within this section of our report, we will be cleaning the Iris Details dataset. The dataset has no missing values, therefore we have opted in not needing to clean the dataset in regards to missing values. We have decided on verifying the following checks for this dataset:\n",
    "\n",
    "- Data Type Check\n",
    "- Consistency Check\n",
    "- Exact Duplicate Check\n",
    "\n",
    "These checks are done to make sure the dataset is consistent with it's defined specifications. Beyond this, the dataset is already clean and ready for testing with decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking column: sepal_length (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'sepal_length' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: sepal_width (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'sepal_width' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: petal_length (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'petal_length' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: petal_width (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'petal_width' match the expected data type.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Data Type Test\n",
    "def data_type_checker(df, attributes, expected_type):\n",
    "     # Convert the column to expected type (ignoring errors for detection)\n",
    "    def is_expected_type(value):\n",
    "        if pd.isna(value):  \n",
    "            return False  \n",
    "        try:\n",
    "            return isinstance(eval(str(value)), expected_type)\n",
    "        except:\n",
    "            return False \n",
    "\n",
    "    # This bit identifies the incorrect entries, making a new dataframe. \n",
    "    for x in range(4):\n",
    "        incorrect_types = df[~df[attributes[x]].apply(is_expected_type)]\n",
    "\n",
    "        # This right here controls the output for the reader of our report to see and understand. \n",
    "        print(f\"Checking column: {attributes[x]} (Expected type: {expected_type.__name__})\")\n",
    "        if incorrect_types.empty:\n",
    "            print(f\"The Data Type Checker suggests all values in '{attributes[x]}' match the expected data type.\")\n",
    "        else:\n",
    "            # This outputs using the values set as parameters in the sentence. \n",
    "            print(f\"The Data Type Checker found {len(incorrect_types)} incorrect entries in '{column}'. \\nFor Example, here are some of the problem entries:\")\n",
    "            display(incorrect_types[[column]].head(5))  # Here we showcase some of the incorrect entries for the user.\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "# This starts the program and runs the function\n",
    "irisAttributes = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "data_type_checker(irisSet, irisAttributes, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No consistency errors found in column 'species'.\n"
     ]
    }
   ],
   "source": [
    "def consistency_checker(df, column, valid_values):\n",
    "\n",
    "    # Find inconsistent values\n",
    "    inconsistent = df[~df[column].isin(valid_values)]\n",
    "    \n",
    "    # Display results\n",
    "    if inconsistent.empty:\n",
    "        print(f\"No consistency errors found in column '{column}'.\")\n",
    "    else:\n",
    "        print(f\"Found {len(inconsistent)} inconsistent values in column '{column}':\")\n",
    "        display(inconsistent[[column]])\n",
    "\n",
    "    return inconsistent\n",
    "\n",
    "# Define valid species values\n",
    "valid_species = {\"setosa\", \"versicolor\", \"virginica\"}\n",
    "\n",
    "# Run the function on your dataset\n",
    "inconsistent_species = consistency_checker(irisSet, \"species\", valid_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "Duplicates removed successfully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  147 non-null    float64\n",
      " 1   sepal_width   147 non-null    float64\n",
      " 2   petal_length  147 non-null    float64\n",
      " 3   petal_width   147 non-null    float64\n",
      " 4   species       147 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "irisSet.info()\n",
    "\n",
    "irisSetNew = irisSet.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "print(\"Duplicates removed successfully.\")\n",
    "\n",
    "irisSetNew.head() \n",
    "irisSetNew.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### b) Numerical feature encoding\n",
    "\n",
    "With numerical feature encoding being an optional requirement for this assignment, we have opted to not feature encode the gaps within our dataset. This is because the range between the values are not substantial enough to justify binning in our calculations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be used\n",
    "# Only created buckers for sepal_length and petal_length because their ranges, 5.9 and 3.6, are the biggest of the 4 numerical values\n",
    "\n",
    "# # Define bucket bins and labels for petal length\n",
    "# petal_bins = [1.0, 2.5, 4.5, 6.9]  # Ranges\n",
    "# petal_labels = [\"Short\", \"Medium\", \"Long\"]\n",
    "\n",
    "# # Define bucket bins and labels for sepal length\n",
    "# sepal_bins = [4.3, 5.5, 6.5, 7.9]  # Ranges\n",
    "# sepal_labels = [\"Small\", \"Medium\", \"Large\"]\n",
    "\n",
    "# # Apply bucketing\n",
    "# irisSetNew[\"petal_length_bucket\"] = pd.cut(irisSetNew[\"petal_length\"], bins=petal_bins, labels=petal_labels, include_lowest=True)\n",
    "# irisSetNew[\"sepal_length_bucket\"] = pd.cut(irisSetNew[\"sepal_length\"], bins=sepal_bins, labels=sepal_labels, include_lowest=True)\n",
    "\n",
    "# # Display a sample of the updated dataset\n",
    "# print(irisSetNew[[\"sepal_length\", \"sepal_length_bucket\", \"petal_length\", \"petal_length_bucket\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be used\n",
    "# Only created buckers for sepal_length and petal_length because their ranges, 5.9 and 3.6, are the biggest of the 4 numerical values\n",
    "\n",
    "# # Define bucket bins and labels for petal length\n",
    "# petal_bins = [1.0, 2.5, 4.5, 6.9]  # Ranges\n",
    "# petal_labels = [\"Short\", \"Medium\", \"Long\"]\n",
    "\n",
    "# # Define bucket bins and labels for sepal length\n",
    "# sepal_bins = [4.3, 5.5, 6.5, 7.9]  # Ranges\n",
    "# sepal_labels = [\"Small\", \"Medium\", \"Large\"]\n",
    "\n",
    "# # Apply bucketing\n",
    "# irisSetNew[\"petal_length_bucket\"] = pd.cut(irisSetNew[\"petal_length\"], bins=petal_bins, labels=petal_labels, include_lowest=True)\n",
    "# irisSetNew[\"sepal_length_bucket\"] = pd.cut(irisSetNew[\"sepal_length\"], bins=sepal_bins, labels=sepal_labels, include_lowest=True)\n",
    "\n",
    "# # Display a sample of the updated dataset\n",
    "# print(irisSetNew[[\"sepal_length\", \"sepal_length_bucket\", \"petal_length\", \"petal_length_bucket\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### c) EDA and Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing numerical features using boxplots to detect potential outliers\n",
    "numerical_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating boxplots for each numerical feature we have\n",
    "for x, col in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(1, 4, x)\n",
    "    sns.boxplot(y=irisSetNew[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "\n",
    "# Proceeding to display the boxplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/neighbors/_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  outlier\n",
       "127           7.2          3.0           5.8          1.6  virginica        1\n",
       "128           7.4          2.8           6.1          1.9  virginica        1\n",
       "129           7.9          3.8           6.4          2.0  virginica        1\n",
       "130           6.4          2.8           5.6          2.2  virginica        1\n",
       "131           6.3          2.8           5.1          1.5  virginica        1\n",
       "132           6.1          2.6           5.6          1.4  virginica        1\n",
       "133           7.7          3.0           6.1          2.3  virginica        1\n",
       "134           6.3          3.4           5.6          2.4  virginica        1\n",
       "135           6.4          3.1           5.5          1.8  virginica        1\n",
       "136           6.0          3.0           4.8          1.8  virginica        1\n",
       "137           6.9          3.1           5.4          2.1  virginica        1\n",
       "138           6.7          3.1           5.6          2.4  virginica        1\n",
       "139           6.9          3.1           5.1          2.3  virginica        1\n",
       "140           6.8          3.2           5.9          2.3  virginica        1\n",
       "141           6.7          3.3           5.7          2.5  virginica        1\n",
       "142           6.7          3.0           5.2          2.3  virginica        1\n",
       "143           6.3          2.5           5.0          1.9  virginica        1\n",
       "144           6.5          3.0           5.2          2.0  virginica        1\n",
       "145           6.2          3.4           5.4          2.3  virginica        1\n",
       "146           5.9          3.0           5.1          1.8  virginica        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier counts: \n",
      "outlier\n",
      "1    147\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Selecting relevant numerical columns for outlier detection\n",
    "outlier_column = [\"sepal_width\"]\n",
    "\n",
    "# Applying LOF to detect outliers via the LOF from Scikit, also assuming 5% outliers. \n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)  \n",
    "outlier_labels = lof.fit_predict(irisSetNew[outlier_column])\n",
    "\n",
    "# Identifying outliers (-1 indicates an outlier)\n",
    "irisSetNew[\"outlier\"] = outlier_labels\n",
    "\n",
    "display(irisSetNew.tail(20))\n",
    "\n",
    "# Count of detected outliers\n",
    "outlier_counts = irisSetNew[\"outlier\"].value_counts()\n",
    "outlier_counts\n",
    "\n",
    "print(f\"Outlier counts: \\n{outlier_counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Prepare data: Separate features (X) and target (y)\n",
    "X = irisSetNew[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "y = irisSetNew[\"species\"]\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define DecisionTreeClassifier with baseline settings\n",
    "baseline_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",      # Use Gini impurity (default choice. Gini impurity is a measurement of how likely it is to misclassify a randomly selected element in a set)\n",
    "    max_depth=5,           # Limit depth to avoid overfitting (Root to leaf node. More depth, more potential to find patterns but also more potential to overfit)\n",
    "    min_samples_split=5,   # Require at least 5 samples (rows of the dataset) to split\n",
    "    min_samples_leaf=3,    # Each leaf should have at least 3 samples (rows of the dataset)\n",
    "    max_features=\"sqrt\",   # Use sqrt of features to split\n",
    "    random_state=42        # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "baseline_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = baseline_tree.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Feature Engineering\n",
    "\n",
    "Feature engineering can be described as creating new features from existing ones to improve prediction accuracy, we have thus decided on the following features: \n",
    "\n",
    "1. Sepal Area -> sepal_area = sepal_length * sepal_width \n",
    "\n",
    "2. Petal Area -> petal_area = petal_length * petal_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>outlier</th>\n",
       "      <th>sepal_area</th>\n",
       "      <th>petal_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>17.85</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>15.04</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species  outlier  \\\n",
       "0           5.1          3.5           1.4          0.2  setosa        1   \n",
       "1           4.9          3.0           1.4          0.2  setosa        1   \n",
       "2           4.7          3.2           1.3          0.2  setosa        1   \n",
       "3           4.6          3.1           1.5          0.2  setosa        1   \n",
       "4           5.0          3.6           1.4          0.2  setosa        1   \n",
       "\n",
       "   sepal_area  petal_area  \n",
       "0       17.85        0.28  \n",
       "1       14.70        0.28  \n",
       "2       15.04        0.26  \n",
       "3       14.26        0.30  \n",
       "4       18.00        0.28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_aggregation = irisSetNew.copy()\n",
    "\n",
    "feature_aggregation[\"sepal_area\"] = feature_aggregation[\"sepal_length\"] * feature_aggregation[\"sepal_width\"]\n",
    "feature_aggregation[\"petal_area\"] = feature_aggregation[\"petal_length\"] * feature_aggregation[\"petal_width\"]\n",
    "\n",
    "display(feature_aggregation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Empiracal Study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_baseline, temp_set_baseline = train_test_split(irisSetNew, test_size=0.3, random_state=42)\n",
    "val_set_baseline, test_set_baseline = train_test_split(temp_set_baseline, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Decision Tree Accuracy: 0.93\n",
      "Precision Scores for each fold: [0.93333333 1.         0.83333333 1.        ]\n",
      "Mean Precision: 0.94\n",
      "Precision with Feature Aggregation: 1.00\n",
      "Precision with Outlier Removal: 0.77\n",
      "Final Model Precision on Test Set: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (assuming irisSetNew is a DataFrame)\n",
    "X = irisSetNew[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "y = irisSetNew[\"species\"]\n",
    "\n",
    "# Split into training (60%), validation (20%), and testing sets (20%)\n",
    "X_train, temp_set, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(temp_set, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define DecisionTreeClassifier with baseline settings\n",
    "baseline_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",      # Use Gini impurity (default choice)\n",
    "    max_depth=5,           # Limit depth to avoid overfitting\n",
    "    min_samples_split=5,   # Require at least 5 samples to split\n",
    "    min_samples_leaf=3,    # Each leaf should have at least 3 samples\n",
    "    max_features=\"sqrt\",   # Use sqrt of features to split\n",
    "    random_state=42        # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "baseline_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = baseline_tree.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline Decision Tree Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Perform 4-fold cross-validation on the validation set\n",
    "precision_scores = cross_val_score(baseline_tree, X_val, y_val, cv=4, scoring='precision_macro')\n",
    "print(f\"Precision Scores for each fold: {precision_scores}\")\n",
    "print(f\"Mean Precision: {np.mean(precision_scores):.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Feature Aggregation Study\n",
    "\n",
    "train_set_fa, temp_set_fa = train_test_split(feature_aggregation, test_size=0.4, random_state=42)\n",
    "val_set_fa, test_set_fa = train_test_split(temp_set_fa, test_size=0.5, random_state=42)\n",
    "\n",
    "X_fa = feature_aggregation.drop(columns=[\"species\"])\n",
    "y_fa = feature_aggregation[\"species\"]\n",
    "\n",
    "feature_aggregation_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train and validate\n",
    "feature_aggregation_tree.fit(train_set_fa[X_fa.columns], train_set_fa[\"species\"])\n",
    "y_val_pred_fa = feature_aggregation_tree.predict(val_set_fa[X_fa.columns])\n",
    "precision_fa = precision_score(val_set_fa[\"species\"], y_val_pred_fa, average='macro')\n",
    "print(f\"Precision with Feature Aggregation: {precision_fa:.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Outlier Removal Study\n",
    "\n",
    "outlier_data = irisSetNew[irisSetNew[\"outlier\"] == 1]\n",
    "train_set_outlier, temp_set_outlier = train_test_split(outlier_data, test_size=0.4, random_state=42)\n",
    "val_set_outlier, test_set_outlier = train_test_split(temp_set_outlier, test_size=0.5, random_state=42)\n",
    "\n",
    "X_outlier = outlier_data.drop(columns=[\"species\"])\n",
    "y_outlier = outlier_data[\"species\"]\n",
    "\n",
    "outlier_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train and validate\n",
    "outlier_tree.fit(train_set_outlier[X_outlier.columns], train_set_outlier[\"species\"])\n",
    "y_val_pred_outlier = outlier_tree.predict(val_set_outlier[X_outlier.columns])\n",
    "precision_outlier = precision_score(val_set_outlier[\"species\"], y_val_pred_outlier, average='macro')\n",
    "print(f\"Precision with Outlier Removal: {precision_outlier:.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Final Model Evaluation on Test Set\n",
    "\n",
    "final_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choosing best performing method (feature aggregation in this case)\n",
    "final_tree.fit(train_set_fa[X_fa.columns], train_set_fa[\"species\"])\n",
    "y_test_pred = final_tree.predict(test_set_fa[X_fa.columns])\n",
    "final_precision = precision_score(test_set_fa[\"species\"], y_test_pred, average='macro')\n",
    "print(f\"Final Model Precision on Test Set: {final_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Decision Tree Accuracy: 0.93\n",
      "Precision Scores for each fold: [0.93333333 1.         0.83333333 1.        ]\n",
      "Mean Precision: 0.94\n",
      "Precision with Feature Aggregation: 1.00\n",
      "Precision with Outlier Removal: 0.77\n",
      "Final Model Precision on Test Set: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (assuming irisSetNew is a DataFrame)\n",
    "X = irisSetNew[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "y = irisSetNew[\"species\"]\n",
    "\n",
    "# Split into training (60%), validation (20%), and testing sets (20%)\n",
    "X_train, temp_set, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(temp_set, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define DecisionTreeClassifier with baseline settings\n",
    "baseline_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",      # Use Gini impurity (default choice)\n",
    "    max_depth=3,           # Limit depth to avoid overfitting\n",
    "    min_samples_split=5,   # Require at least 5 samples to split\n",
    "    min_samples_leaf=3,    # Each leaf should have at least 3 samples\n",
    "    max_features=\"sqrt\",   # Use sqrt of features to split\n",
    "    random_state=42        # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "baseline_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = baseline_tree.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline Decision Tree Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Perform 4-fold cross-validation on the validation set\n",
    "precision_scores = cross_val_score(baseline_tree, X_val, y_val, cv=4, scoring='precision_macro')\n",
    "print(f\"Precision Scores for each fold: {precision_scores}\")\n",
    "print(f\"Mean Precision: {np.mean(precision_scores):.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Feature Aggregation Study\n",
    "\n",
    "train_set_fa, temp_set_fa = train_test_split(feature_aggregation, test_size=0.4, random_state=42)\n",
    "val_set_fa, test_set_fa = train_test_split(temp_set_fa, test_size=0.5, random_state=42)\n",
    "\n",
    "X_fa = feature_aggregation.drop(columns=[\"species\"])\n",
    "y_fa = feature_aggregation[\"species\"]\n",
    "\n",
    "feature_aggregation_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=3,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train and validate\n",
    "feature_aggregation_tree.fit(train_set_fa[X_fa.columns], train_set_fa[\"species\"])\n",
    "y_val_pred_fa = feature_aggregation_tree.predict(val_set_fa[X_fa.columns])\n",
    "precision_fa = precision_score(val_set_fa[\"species\"], y_val_pred_fa, average='macro')\n",
    "print(f\"Precision with Feature Aggregation: {precision_fa:.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Outlier Removal Study\n",
    "\n",
    "outlier_data = irisSetNew[irisSetNew[\"outlier\"] == 1]\n",
    "train_set_outlier, temp_set_outlier = train_test_split(outlier_data, test_size=0.4, random_state=42)\n",
    "val_set_outlier, test_set_outlier = train_test_split(temp_set_outlier, test_size=0.5, random_state=42)\n",
    "\n",
    "X_outlier = outlier_data.drop(columns=[\"species\"])\n",
    "y_outlier = outlier_data[\"species\"]\n",
    "\n",
    "outlier_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=3,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train and validate\n",
    "outlier_tree.fit(train_set_outlier[X_outlier.columns], train_set_outlier[\"species\"])\n",
    "y_val_pred_outlier = outlier_tree.predict(val_set_outlier[X_outlier.columns])\n",
    "precision_outlier = precision_score(val_set_outlier[\"species\"], y_val_pred_outlier, average='macro')\n",
    "print(f\"Precision with Outlier Removal: {precision_outlier:.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Final Model Evaluation on Test Set\n",
    "\n",
    "final_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=3,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choosing best performing method (feature aggregation in this case)\n",
    "final_tree.fit(train_set_fa[X_fa.columns], train_set_fa[\"species\"])\n",
    "y_test_pred = final_tree.predict(test_set_fa[X_fa.columns])\n",
    "final_precision = precision_score(test_set_fa[\"species\"], y_test_pred, average='macro')\n",
    "print(f\"Final Model Precision on Test Set: {final_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Results of Analysis\n",
    "\n",
    "#### a)\n",
    "In our study, we divided our dataset into three subsets: a training set (60%), a validation set (20%), and a test set (20%). The training set was used to train the models, while the validation set allowed us to fine-tune our approach using 4-fold cross-validation. Finally, the test set was left untouched until the final evaluation to ensure an unbiased assessment of the best-performing model.\n",
    "\n",
    "For evaluation, we primarily used precision as our metric, as it measures the correctness of positive classifications. Additionally, accuracy was observed to provide an overall performance measure.\n",
    "\n",
    "We started with a baseline Decision Tree Classifier, using default parameters such as `criterion=\"gini\"`, `max_depth=5`, `min_samples_split=5`, and `min_samples_leaf=3`. This model, evaluated on the validation set, achieved an accuracy of 93%, which set a benchmark for comparison.\n",
    "\n",
    "To explore ways to improve performance, we experimented with different data modifications. First, we applied Feature Aggregation, where additional features were derived to enhance classification ability. This resulted in a perfect precision score of 1.00, indicating a significant improvement. Next, we tested an Outlier Removal approach, which led to a drop in precision to 0.77. This suggested that the removed outliers contained meaningful information that helped in classification rather than being mere noise.\n",
    "\n",
    "#### b)\n",
    "Further, we experimented with hyperparameter tuning, adjusting max_depth, criterion, and min_samples_split. Initially, having max_depth set at 5 caused the Outlier Model to achieve unexpectedly high accuracy, which raised concerns about potential overfitting, we tweaked it to `max_depth=3` and saw different results. We adjusted various parameters and re-evaluated different configurations, yet Feature Aggregation remained the strongest approach, consistently yielding the best empirical results.\n",
    "\n",
    "#### c)\n",
    "Based on these experiments, Feature Aggregation was chosen as the final model. This model was trained on the training set and evaluated on the completely unseen test set, where it maintained high precision, confirming its effectiveness. Our experiments demonstrated clear variations across different settings. Feature Aggregation significantly improved classification performance, achieving perfect precision, while Outlier Removal negatively impacted results, reducing precision to 0.77. This unexpected drop suggested that some of the outliers played a crucial role in distinguishing between species rather than acting as noise.\n",
    "\n",
    "Comparing cross-validation results with final test set performance, we observed consistent outcomes, indicating that the model was not overfitting. The validation precision from 4-fold cross-validation closely matched the final test precision, proving that our model effectively generalized to unseen data. This confirmed that our approach, particularly Feature Aggregation, successfully enhanced classification without introducing excessive reliance on specific data patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "Through extensive experimentation, we determined that Feature Aggregation was the most effective enhancement for our Decision Tree Classifier. The baseline model performed well, but Feature Aggregation provided a significant boost, achieving perfect precision. Meanwhile, Outlier Removal negatively impacted performance, indicating that detected outliers contained useful information rather than noise.\n",
    "\n",
    "Most importantly, our cross-validation results were consistent with test set results, reinforcing that our approach was robust and generalizable. These findings highlight the importance of carefully considering data preprocessing techniques in model optimization. For future improvements, we could explore additional feature engineering techniques and ensemble models such as Random Forests or Gradient Boosting to further refine classification performance.\n",
    "\n",
    "Overall, this assignment has taught us the value and importance of choosing a good dataset, and the importance of tweaking parameters to play with the different decisionTrees that can be created. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
