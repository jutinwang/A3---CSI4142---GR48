{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Group 48 - Assignment 3 - Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this report, we perform an empirical study in which we evaluate a decision tree approach on a classification task.\n",
    "\n",
    "1. Clean the data \n",
    "2. (Optional) Groups different numerical values into bins or buckets \n",
    "3. Conduct an EDA (Exploritory Data Analysis) to visualize data and find outliers in the features using LOF (Local Outlier Factor)\n",
    "4. Explore the DecisionTreeClassifier method suggested in scikit-learn and choose a baseline setting by looking at the parameters (splitting criterion (gini, entropy), max_depth, min_samples_split, etc)\n",
    "5. Program a feature aggregator to create 2 additional features\n",
    "6. Conduct an empirical study\n",
    "7. Analyize the results\n",
    "8. Discuss the outliers and feature aggregation, as well as the results on the unseen test set compare to the cross-validation results\n",
    "\n",
    "#### Group 48 Members\n",
    "- Ali Bhangu - 300234254\n",
    "- Justin Wang - 300234186\n",
    "\n",
    "<br>\n",
    "\n",
    "## Dataset Description: Iris Dataset\n",
    "\n",
    "- **Dataset Name:** Iris Dataset  \n",
    "- **Author:** Himanshi Nakrani \n",
    "- **Purpose:** This dataset was found on Kaggle.com, and is used in numerous data science projects across the world. For our purposes, this will serve as the dataset we use for Assignment 3 Part 2. \n",
    "---\n",
    "\n",
    "### Dataset Shape\n",
    "- **Rows:** 150  \n",
    "- **Columns:** 5  \n",
    "\n",
    "---\n",
    "\n",
    "### Features & Descriptions  \n",
    "\n",
    "| Feature Name    | Data Type  | Category    | Description |\n",
    "|----------------|------------|-------------|-------------|\n",
    "| `sepal_length` | Float      | Numerical   | Length of the sepal in cm |\n",
    "| `sepal_width`  | Float      | Numerical   | Width of the sepal in cm |\n",
    "| `petal_length` | Float      | Numerical   | Length of the petal in cm |\n",
    "| `petal_width`  | Float      | Numerical   | Width of the petal in cm |\n",
    "| `species`      | String     | Categorical | The species of the iris flower (Setosa, Versicolor, Virginica) |\n",
    "Would you like any modifications or additional insights on this dataset? ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1006  100  1006    0     0   2988      0 --:--:-- --:--:-- --:--:-- 13594\n",
      "Extracting dataset...\n",
      "Archive:  iris-dataset.zip\n",
      "  inflating: ./iris.csv              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "zip_path = \"iris-dataset.zip\"\n",
    "csv_path = \"iris.csv\"  # Adjust this if the extracted file has a different name\n",
    "\n",
    "# Delete existing CSV if present\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Existing {csv_path} found. Deleting and re-extracting...\")\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# Download dataset using curl (Bash command in Jupyter Notebook)\n",
    "!curl -L -o {zip_path} https://www.kaggle.com/api/v1/datasets/download/himanshunakrani/iris-dataset\n",
    "\n",
    "# Extract the ZIP file in the current folder\n",
    "print(\"Extracting dataset...\")\n",
    "!unzip -o {zip_path} -d .\n",
    "\n",
    "# Verify that the CSV exists after extraction\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {csv_path}. Ensure the ZIP file was correctly extracted.\")\n",
    "\n",
    "# Load dataset\n",
    "cafeSet = pd.read_csv(csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
