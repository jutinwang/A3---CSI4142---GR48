{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Group 48 - Assignment 3 - Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this report, we perform an empirical study in which we evaluate a decision tree approach on a classification task.\n",
    "\n",
    "1. Clean the data \n",
    "2. (Optional) Groups different numerical values into bins or buckets \n",
    "3. Conduct an EDA (Exploritory Data Analysis) to visualize data and find outliers in the features using LOF (Local Outlier Factor)\n",
    "4. Explore the DecisionTreeClassifier method suggested in scikit-learn and choose a baseline setting by looking at the parameters (splitting criterion (gini, entropy), max_depth, min_samples_split, etc)\n",
    "5. Program a feature aggregator to create 2 additional features\n",
    "6. Conduct an empirical study\n",
    "7. Analyize the results\n",
    "8. Discuss the outliers and feature aggregation, as well as the results on the unseen test set compare to the cross-validation results\n",
    "\n",
    "#### Group 48 Members\n",
    "- Ali Bhangu - 300234254\n",
    "- Justin Wang - 300234186\n",
    "\n",
    "<br>\n",
    "\n",
    "## Dataset Description: Iris Dataset\n",
    "\n",
    "- **Dataset Name:** Iris Dataset  \n",
    "- **Author:** Himanshi Nakrani \n",
    "- **Purpose:** This dataset was found on Kaggle.com, and is used in numerous data science projects across the world. For our purposes, this will serve as the dataset we use for Assignment 3 Part 2. \n",
    "---\n",
    "\n",
    "### Dataset Shape\n",
    "- **Rows:** 150  \n",
    "- **Columns:** 5  \n",
    "\n",
    "---\n",
    "\n",
    "### Features & Descriptions  \n",
    "\n",
    "| Feature Name    | Data Type  | Category    | Description |\n",
    "|----------------|------------|-------------|-------------|\n",
    "| `sepal_length` | Float      | Numerical   | Length of the sepal in cm |\n",
    "| `sepal_width`  | Float      | Numerical   | Width of the sepal in cm |\n",
    "| `petal_length` | Float      | Numerical   | Length of the petal in cm |\n",
    "| `petal_width`  | Float      | Numerical   | Width of the petal in cm |\n",
    "| `species`      | String     | Categorical | The species of the iris flower (Setosa, Versicolor, Virginica) |\n",
    "Would you like any modifications or additional insights on this dataset? ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as npy\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import os as os\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing iris.csv found. Deleting and re-extracting...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1006  100  1006    0     0   3350      0 --:--:-- --:--:-- --:--:--  3350\n",
      "Extracting dataset...\n",
      "Archive:  iris-dataset.zip\n",
      "  inflating: ./iris.csv              \n",
      "Dataset loaded successfully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "zip_path = \"iris-dataset.zip\"\n",
    "csv_path = \"iris.csv\"  # Adjust this if the extracted file has a different name\n",
    "\n",
    "# Delete existing CSV if present\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Existing {csv_path} found. Deleting and re-extracting...\")\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# Download dataset using curl (Bash command in Jupyter Notebook)\n",
    "!curl -L -o {zip_path} https://www.kaggle.com/api/v1/datasets/download/himanshunakrani/iris-dataset\n",
    "\n",
    "# Extract the ZIP file in the current folder\n",
    "print(\"Extracting dataset...\")\n",
    "!unzip -o {zip_path} -d .\n",
    "\n",
    "# Verify that the CSV exists after extraction\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {csv_path}. Ensure the ZIP file was correctly extracted.\")\n",
    "\n",
    "# Load dataset\n",
    "irisSet = pd.read_csv(csv_path)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "irisSet.head()\n",
    "irisSet.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### a) Clean Data\n",
    "\n",
    "Within this section of our report, we will be cleaning the Iris Details dataset. The dataset has no missing values, therefore we have opted in not needing to clean the dataset in regards to missing values. We have decided on verifying the following checks for this dataset:\n",
    "\n",
    "- Data Type Check\n",
    "- Consistency Check\n",
    "- Exact Duplicate Check\n",
    "\n",
    "As beyond this, the dataset is already clean and ready for regression testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking column: sepal_length (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'sepal_length' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: sepal_width (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'sepal_width' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: petal_length (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'petal_length' match the expected data type.\n",
      "\n",
      "\n",
      "Checking column: petal_width (Expected type: float)\n",
      "The Data Type Checker suggests all values in 'petal_width' match the expected data type.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Data Type Test\n",
    "def data_type_checker(df, attributes, expected_type):\n",
    "     # Convert the column to expected type (ignoring errors for detection)\n",
    "    def is_expected_type(value):\n",
    "        if pd.isna(value):  \n",
    "            return False  \n",
    "        try:\n",
    "            return isinstance(eval(str(value)), expected_type)\n",
    "        except:\n",
    "            return False \n",
    "\n",
    "    # This bit identifies the incorrect entries, making a new dataframe. \n",
    "    for x in range(4):\n",
    "        incorrect_types = df[~df[attributes[x]].apply(is_expected_type)]\n",
    "\n",
    "        # This right here controls the output for the reader of our report to see and understand. \n",
    "        print(f\"Checking column: {attributes[x]} (Expected type: {expected_type.__name__})\")\n",
    "        if incorrect_types.empty:\n",
    "            print(f\"The Data Type Checker suggests all values in '{attributes[x]}' match the expected data type.\")\n",
    "        else:\n",
    "            # This outputs using the values set as parameters in the sentence. \n",
    "            print(f\"The Data Type Checker found {len(incorrect_types)} incorrect entries in '{column}'. \\nFor Example, here are some of the problem entries:\")\n",
    "            display(incorrect_types[[column]].head(5))  # Here we showcase some of the incorrect entries for the user.\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "# This starts the program and runs the function\n",
    "irisAttributes = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "data_type_checker(irisSet, irisAttributes, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No consistency errors found in column 'species'.\n"
     ]
    }
   ],
   "source": [
    "def consistency_checker(df, column, valid_values):\n",
    "\n",
    "    # Find inconsistent values\n",
    "    inconsistent = df[~df[column].isin(valid_values)]\n",
    "    \n",
    "    # Display results\n",
    "    if inconsistent.empty:\n",
    "        print(f\"No consistency errors found in column '{column}'.\")\n",
    "    else:\n",
    "        print(f\"Found {len(inconsistent)} inconsistent values in column '{column}':\")\n",
    "        display(inconsistent[[column]])\n",
    "\n",
    "    return inconsistent\n",
    "\n",
    "# Please enter the various attrivutes below to perform the data cleaning process on the dataset. \n",
    "attributes = ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "# Define valid species values\n",
    "valid_species = {\"setosa\", \"versicolor\", \"virginica\"}\n",
    "\n",
    "# Run the function on your dataset\n",
    "inconsistent_species = consistency_checker(irisSet, \"species\", valid_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "Duplicates removed successfully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  147 non-null    float64\n",
      " 1   sepal_width   147 non-null    float64\n",
      " 2   petal_length  147 non-null    float64\n",
      " 3   petal_width   147 non-null    float64\n",
      " 4   species       147 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "irisSet.info()\n",
    "\n",
    "irisSetNew = irisSet.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "print(\"Duplicates removed successfully.\")\n",
    "\n",
    "irisSetNew.head() \n",
    "irisSetNew.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
